{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from keras import layers \n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D \n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D \n",
    "from keras.models import Model \n",
    "from keras.preprocessing import image \n",
    "from keras.utils import layer_utils \n",
    "from keras.utils.data_utils import get_file \n",
    "from keras.applications.imagenet_utils import preprocess_input \n",
    "import pydot \n",
    "from IPython.display import SVG \n",
    "from keras.utils.vis_utils import model_to_dot \n",
    "from keras.utils import plot_model \n",
    "import kt_utils \n",
    "import keras.backend as K \n",
    "K.set_image_data_format('channels_last') \n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.pyplot import imshow \n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 600\n",
      "number of test examples = 150\n",
      "X_train shape: (600, 64, 64, 3)\n",
      "Y_train shape: (600, 1)\n",
      "X_test shape: (150, 64, 64, 3)\n",
      "Y_test shape: (150, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = kt_utils.load_dataset()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig/255\n",
    "X_test = X_test_orig/255\n",
    "\n",
    "# reshape\n",
    "Y_train = Y_train_orig.T\n",
    "Y_test = Y_test_orig.T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0])) \n",
    "print (\"number of test examples = \" + str(X_test.shape[0])) \n",
    "print (\"X_train shape: \" + str(X_train.shape)) \n",
    "print (\"Y_train shape: \" + str(Y_train.shape)) \n",
    "print (\"X_test shape: \" + str(X_test.shape)) \n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HappyModel(input_shape):\n",
    "    \"\"\"\n",
    "    实现一个检测笑容的模型\n",
    "\n",
    "    参数：\n",
    "        input_shape - 输入的数据的维度\n",
    "    返回：\n",
    "        model - 创建的Keras的模型\n",
    "\n",
    "    \"\"\"\n",
    "    # 定义一个tensor的placeholder 维度为input_shape\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    # 使用0填充，X_input周围填充0\n",
    "    X = ZeroPadding2D((3,3))(X_input)\n",
    "    \n",
    "    # 对X使用conv -> bn -> relu块\n",
    "    X = Conv2D(32,(7,7),strides=(1,1),name= 'conv0')(X)\n",
    "    X = BatchNormalization(axis=3,name='bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # 最大值池化层\n",
    "    X= MaxPooling2D((2,2),name='max_pool')(X)\n",
    "    \n",
    "    # 降维 矩阵转换成向量 + 全连接层\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1,activation='sigmoid',name='fc')(X)\n",
    "    \n",
    "    # 创建一个模型\n",
    "    model = Model(inputs = X_input,outputs=X,name='HappyModel')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.9987 - acc: 0.6667\n",
      "Epoch 2/40\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.2035 - acc: 0.9233\n",
      "Epoch 3/40\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.1497 - acc: 0.9483\n",
      "Epoch 4/40\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.1464 - acc: 0.9367\n",
      "Epoch 5/40\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.0997 - acc: 0.9633\n",
      "Epoch 6/40\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.0688 - acc: 0.9833\n",
      "Epoch 7/40\n",
      "600/600 [==============================] - 9s 16ms/step - loss: 0.0671 - acc: 0.9817\n",
      "Epoch 8/40\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.0634 - acc: 0.9850\n",
      "Epoch 9/40\n",
      "600/600 [==============================] - 9s 16ms/step - loss: 0.0468 - acc: 0.9900\n",
      "Epoch 10/40\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.0473 - acc: 0.9850\n",
      "Epoch 11/40\n",
      "600/600 [==============================] - 9s 16ms/step - loss: 0.0415 - acc: 0.9917\n",
      "Epoch 12/40\n",
      "600/600 [==============================] - 9s 16ms/step - loss: 0.0449 - acc: 0.9900\n",
      "Epoch 13/40\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.0401 - acc: 0.9900\n",
      "Epoch 14/40\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.0321 - acc: 0.9883\n",
      "Epoch 15/40\n",
      "600/600 [==============================] - 9s 16ms/step - loss: 0.0481 - acc: 0.9867\n",
      "Epoch 16/40\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.0364 - acc: 0.9867\n",
      "Epoch 17/40\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.0323 - acc: 0.9917\n",
      "Epoch 18/40\n",
      "600/600 [==============================] - 9s 16ms/step - loss: 0.0257 - acc: 0.9900\n",
      "Epoch 19/40\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.0253 - acc: 0.9933\n",
      "Epoch 20/40\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.0355 - acc: 0.9883\n",
      "Epoch 21/40\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.0248 - acc: 0.9967\n",
      "Epoch 22/40\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.0276 - acc: 0.9933\n",
      "Epoch 23/40\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.0222 - acc: 0.9933\n",
      "Epoch 24/40\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.0328 - acc: 0.9883\n",
      "Epoch 25/40\n",
      "600/600 [==============================] - 12s 19ms/step - loss: 0.0335 - acc: 0.9950\n",
      "Epoch 26/40\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0284 - acc: 0.9900\n",
      "Epoch 27/40\n",
      "600/600 [==============================] - 12s 20ms/step - loss: 0.0183 - acc: 0.9950\n",
      "Epoch 28/40\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0179 - acc: 0.9950\n",
      "Epoch 29/40\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.0197 - acc: 0.9933\n",
      "Epoch 30/40\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0159 - acc: 0.9950\n",
      "Epoch 31/40\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.0090 - acc: 0.9967\n",
      "Epoch 32/40\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 33/40\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0109 - acc: 0.9967\n",
      "Epoch 34/40\n",
      "600/600 [==============================] - 12s 20ms/step - loss: 0.0126 - acc: 0.9967\n",
      "Epoch 35/40\n",
      "600/600 [==============================] - 12s 21ms/step - loss: 0.0188 - acc: 0.9967\n",
      "Epoch 36/40\n",
      "600/600 [==============================] - 14s 24ms/step - loss: 0.0451 - acc: 0.9817\n",
      "Epoch 37/40\n",
      "600/600 [==============================] - 13s 21ms/step - loss: 0.0745 - acc: 0.9683\n",
      "Epoch 38/40\n",
      "600/600 [==============================] - 13s 22ms/step - loss: 0.0182 - acc: 0.9967\n",
      "Epoch 39/40\n",
      "600/600 [==============================] - 12s 20ms/step - loss: 0.0197 - acc: 0.9950\n",
      "Epoch 40/40\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.0111 - acc: 0.9967\n",
      "150/150 [==============================] - 1s 7ms/step\n",
      "误差值 = 0.4839847481250763\n",
      "准确度 = 0.8333333349227905\n"
     ]
    }
   ],
   "source": [
    "# 创建模型实体\n",
    "happy_model = HappyModel(X_train.shape[1:])\n",
    "# 编译模型\n",
    "happy_model.compile(\"adam\",\"binary_crossentropy\",metrics=['accuracy'])\n",
    "# 训练模型  6-10mins\n",
    "happy_model.fit(X_train, Y_train, epochs=40, batch_size=50)\n",
    "# 评估模型\n",
    "preds = happy_model.evaluate(X_test, Y_test, batch_size=32, verbose=1, sample_weight=None) \n",
    "print (\"误差值 = \" + str(preds[0])) \n",
    "print (\"准确度 = \" + str(preds[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path=''\n",
    "img = image.load_img(img_path, target_size=(64, 64)) \n",
    "imshow(img) \n",
    "x = image.img_to_array(img) \n",
    "x = np.expand_dims(x, axis=0) \n",
    "x = preprocess_input(x) \n",
    "print(happy_model.predict(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
