{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "\n",
    "#------------用于绘制模型细节，可选--------------#\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "#------------------------------------------------#\n",
    "\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import fr_utils\n",
    "from inception_blocks_v2 import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参数数量：3743280\n"
     ]
    }
   ],
   "source": [
    "#获取模型\n",
    "FRmodel = faceRecoModel(input_shape=(3,96,96))\n",
    "\n",
    "#打印模型的总参数数量\n",
    "print(\"参数数量：\" + str(FRmodel.count_params()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------用于绘制模型细节，可选--------------#\n",
    "# %matplotlib inline\n",
    "# plot_model(FRmodel, to_file='FRmodel.png')\n",
    "# SVG(model_to_dot(FRmodel).create(prog='dot', format='svg'))\n",
    "#------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "    \"\"\"\n",
    "    根据公式（4）实现三元组损失函数\n",
    "\n",
    "    参数：\n",
    "        y_true -- true标签，当你在Keras里定义了一个损失函数的时候需要它，但是这里不需要。\n",
    "        y_pred -- 列表类型，包含了如下参数：\n",
    "            anchor -- 给定的“anchor”图像的编码，维度为(None,128)\n",
    "            positive -- “positive”图像的编码，维度为(None,128)\n",
    "            negative -- “negative”图像的编码，维度为(None,128)\n",
    "        alpha -- 超参数，阈值\n",
    "\n",
    "    返回：\n",
    "        loss -- 实数，损失的值\n",
    "    \"\"\"\n",
    "    #获取anchor, positive, negative的图像编码\n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "\n",
    "    #第一步：计算\"anchor\" 与 \"positive\"之间编码的距离，这里需要使用axis=-1\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,positive)),axis=-1)\n",
    "\n",
    "    #第二步：计算\"anchor\" 与 \"negative\"之间编码的距离，这里需要使用axis=-1\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,negative)),axis=-1)\n",
    "\n",
    "    #第三步：减去之前的两个距离，然后加上alpha\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist,neg_dist),alpha)\n",
    "\n",
    "    #通过取带零的最大值和对训练样本的求和来计算整个公式\n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss,0))\n",
    "\n",
    "    return loss\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 528.1432\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as test:\n",
    "    tf.set_random_seed(1)\n",
    "    y_true = (None, None, None)\n",
    "    y_pred = (tf.random_normal([3, 128], mean=6, stddev=0.1, seed = 1),\n",
    "              tf.random_normal([3, 128], mean=1, stddev=1, seed = 1),\n",
    "              tf.random_normal([3, 128], mean=3, stddev=4, seed = 1))\n",
    "    loss = triplet_loss(y_true, y_pred)\n",
    "\n",
    "    print(\"loss = \" + str(loss.eval()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "执行了：2分0秒\n"
     ]
    }
   ],
   "source": [
    "#开始时间\n",
    "start_time = time.clock()\n",
    "\n",
    "#编译模型\n",
    "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
    "\n",
    "#加载权值\n",
    "fr_utils.load_weights_from_FaceNet(FRmodel)\n",
    "\n",
    "#结束时间\n",
    "end_time = time.clock()\n",
    "\n",
    "#计算时差\n",
    "minium = end_time - start_time\n",
    "\n",
    "print(\"执行了：\" + str(int(minium / 60)) + \"分\" + str(int(minium%60)) + \"秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 人脸验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = {}\n",
    "database[\"danielle\"] = fr_utils.img_to_encoding(\"images/danielle.png\", FRmodel)\n",
    "database[\"younes\"] = fr_utils.img_to_encoding(\"images/younes.jpg\", FRmodel)\n",
    "database[\"tian\"] = fr_utils.img_to_encoding(\"images/tian.jpg\", FRmodel)\n",
    "database[\"andrew\"] = fr_utils.img_to_encoding(\"images/andrew.jpg\", FRmodel)\n",
    "database[\"kian\"] = fr_utils.img_to_encoding(\"images/kian.jpg\", FRmodel)\n",
    "database[\"dan\"] = fr_utils.img_to_encoding(\"images/dan.jpg\", FRmodel)\n",
    "database[\"sebastiano\"] = fr_utils.img_to_encoding(\"images/sebastiano.jpg\", FRmodel)\n",
    "database[\"bertrand\"] = fr_utils.img_to_encoding(\"images/bertrand.jpg\", FRmodel)\n",
    "database[\"kevin\"] = fr_utils.img_to_encoding(\"images/kevin.jpg\", FRmodel)\n",
    "database[\"felix\"] = fr_utils.img_to_encoding(\"images/felix.jpg\", FRmodel)\n",
    "database[\"benoit\"] = fr_utils.img_to_encoding(\"images/benoit.jpg\", FRmodel)\n",
    "database[\"arnaud\"] = fr_utils.img_to_encoding(\"images/arnaud.jpg\", FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(image_path, identity, database, model):\n",
    "    \"\"\"\n",
    "    对“identity”与“image_path”的编码进行验证。\n",
    "\n",
    "    参数：\n",
    "        image_path -- 摄像头的图片。\n",
    "        identity -- 字符类型，想要验证的人的名字。\n",
    "        database -- 字典类型，包含了成员的名字信息与对应的编码。\n",
    "        model -- 在Keras的模型的实例。\n",
    "\n",
    "    返回：\n",
    "        dist -- 摄像头的图片与数据库中的图片的编码的差距。\n",
    "        is_open_door -- boolean,是否该开门。\n",
    "    \"\"\"\n",
    "    #第一步：计算图像的编码，使用fr_utils.img_to_encoding()来计算。\n",
    "    encoding = fr_utils.img_to_encoding(image_path, model)\n",
    "\n",
    "    #第二步：计算与数据库中保存的编码的差距\n",
    "    dist = np.linalg.norm(encoding - database[identity])\n",
    "\n",
    "    #第三步：判断是否打开门\n",
    "    if dist < 0.7:\n",
    "        print(\"欢迎 \" + str(identity) + \"回家！\")\n",
    "        is_door_open = True\n",
    "    else:\n",
    "        print(\"经验证，您与\" + str(identity) + \"不符！\")\n",
    "        is_door_open = False\n",
    "\n",
    "    return dist, is_door_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "欢迎 younes回家！\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6710074, True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify(\"images/camera_0.jpg\",\"younes\",database,FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经验证，您与kian不符！\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.85800153, False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify(\"images/camera_2.jpg\", \"kian\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 人脸识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def who_is_it(image_path, database,model):\n",
    "    \"\"\"\n",
    "    根据指定的图片来进行人脸识别\n",
    "\n",
    "    参数：\n",
    "        images_path -- 图像地址\n",
    "        database -- 包含了名字与编码的字典\n",
    "        model -- 在Keras中的模型的实例。\n",
    "\n",
    "    返回：\n",
    "        min_dist -- 在数据库中与指定图像最相近的编码。\n",
    "        identity -- 字符串类型，与min_dist编码相对应的名字。\n",
    "    \"\"\"\n",
    "    #步骤1：计算指定图像的编码，使用fr_utils.img_to_encoding()来计算。\n",
    "    encoding = fr_utils.img_to_encoding(image_path, model)\n",
    "\n",
    "    #步骤2 ：找到最相近的编码\n",
    "    ## 初始化min_dist变量为足够大的数字，这里设置为100\n",
    "    min_dist = 100\n",
    "\n",
    "    ## 遍历数据库找到最相近的编码\n",
    "    for (name,db_enc) in database.items():\n",
    "        ### 计算目标编码与当前数据库编码之间的L2差距。\n",
    "        dist = np.linalg.norm(encoding - db_enc)\n",
    "\n",
    "        ### 如果差距小于min_dist，那么就更新名字与编码到identity与min_dist中。\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            identity = name\n",
    "\n",
    "    # 判断是否在数据库中\n",
    "    if min_dist > 0.7:\n",
    "        print(\"抱歉，您的信息不在数据库中。\")\n",
    "\n",
    "    else:\n",
    "        print(\"姓名\" + str(identity) + \"  差距：\" + str(min_dist))\n",
    "\n",
    "    return min_dist, identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "姓名younes  差距：0.6710074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6710074, 'younes')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "who_is_it(\"images/camera_0.jpg\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
